{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6972e44a-d30c-43b0-bab8-6c873019411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import warnings\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from scipy import misc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from load_data.pair_loader import *\n",
    "from algorithm.SRNet import Srnet\n",
    "from utils.helper import *\n",
    "from utils.AverageMeter import AverageMeter\n",
    "\n",
    "cfg = load_config()\n",
    "device = torch.device(cfg.device)\n",
    "run_folder = create_folder(cfg.run_folder)\n",
    "# Print the configuration.\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s', handlers=[\n",
    "    logging.FileHandler(os.path.join(run_folder, f'run.log')), logging.StreamHandler(sys.stdout)])\n",
    "logging.info(\"Experiment Configuration:\")\n",
    "logging.info(\"CUDA_VISIBLE_DEVICESï¼š{}\".format(os.getenv('CUDA_VISIBLE_DEVICES')))\n",
    "logging.info(cfg)\n",
    "logging.info(\"run_folder:{}\".format(run_folder))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# to be reproducible\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    if cfg.seed is not None:\n",
    "        np.random.seed(cfg.seed)  # Numpy module.\n",
    "        random.seed(cfg.seed)  # Python random module.\n",
    "        torch.manual_seed(cfg.seed)  # Sets the seed for generating random numbers.\n",
    "        torch.cuda.manual_seed(cfg.seed)  # Sets the seed for generating random numbers for the current GPU.\n",
    "        torch.cuda.manual_seed_all(cfg.seed)  # Sets the seed for generating random numbers on all GPUs.\n",
    "        cudnn.deterministic = True\n",
    "\n",
    "        warnings.warn('You have choosen to seed training. '\n",
    "                      'This will turn on the CUDNN deterministic setting, '\n",
    "                      'which can slow down your training considerably! '\n",
    "                      'You may see unexpected behavior when restarting '\n",
    "                      'from checkpoints.')\n",
    "        logging.info('torch.cuda is available!')\n",
    "\n",
    "\n",
    "def adjust_learning_rate(epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decays by 10 every 80 epochs\"\"\"\n",
    "    lr = cfg.lr * (0.1 ** (epoch // 80))\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "\n",
    "\n",
    "# Weight initialization for conv layers and fc layers\n",
    "def inti_SRNet_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias.data, 0.2)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        torch.nn.init.normal_(m.weight.data, mean=0., std=0.01)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.)\n",
    "\n",
    "\n",
    "# model creation and initialization\n",
    "ana_model = Srnet()\n",
    "ana_model.to(device)\n",
    "ana_model = ana_model.apply(inti_SRNet_weights)\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adamax(ana_model.parameters(), lr=cfg.lr, betas=(0.9, 0.999), eps=1e-8, weight_decay=0)\n",
    "# data loaders\n",
    "train_data = Dataset_Load(cfg.cover_path, cfg.stego_path, cfg.train_size,\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.Resize((cfg.resize, cfg.resize)),\n",
    "                                          transforms.Grayscale(),\n",
    "                                          dataset.ToTensor()]))\n",
    "\n",
    "val_data = Dataset_Load(cfg.valid_cover_path, cfg.valid_stego_path, cfg.val_size,\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.Resize((cfg.resize, cfg.resize)),\n",
    "                                          transforms.Grayscale(),\n",
    "                                          dataset.ToTensor()]))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=cfg.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=cfg.batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    if cfg.has_ckp is True:\n",
    "        ana_ckp = torch.load(\"\")  # Fill in the path of the model checkpoint.\n",
    "        ana_model.load_state_dict(ana_ckp[''])  # model weights\n",
    "        optimizer.load_state_dict(ana_ckp[''])  # parameters of the optimizer\n",
    "        logging.info(\"Have loaded analyzer checkpoint.\")\n",
    "\n",
    "    for epoch in range(cfg.start_epoch, cfg.num_epochs + 1):\n",
    "        ana_model.train()\n",
    "        st_time = time.time()\n",
    "        adjust_learning_rate(epoch)\n",
    "\n",
    "        # Save relevant metrics in dictionaries.\n",
    "        train_losses_dict = defaultdict(AverageMeter)\n",
    "        train_acc_dict = defaultdict(AverageMeter)\n",
    "        val_losses_dict = defaultdict(AverageMeter)\n",
    "        val_acc_dict = defaultdict(AverageMeter)\n",
    "\n",
    "        step = 1\n",
    "\n",
    "        for i, train_batch in enumerate(train_loader):\n",
    "            images = torch.cat((train_batch['cover'], train_batch['stego']), 0).to(device, dtype=torch.float)\n",
    "            labels = torch.cat((train_batch['label'][0], train_batch['label'][1]), 0).to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = ana_model(images)\n",
    "\n",
    "            ana_loss = criterion_ce(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            ana_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            prediction = outputs.data.max(1)[1]\n",
    "            accuracy = prediction.eq(labels.data).sum() * 100.0 / (labels.size()[0])\n",
    "\n",
    "            train_losses_dict['ana_loss'].update(ana_loss.item(), images.size(0))\n",
    "            train_acc_dict['accuracy'].update(accuracy.item(), images.size(0))\n",
    "\n",
    "            if step % cfg.print_freq == 0 or step == (len(train_loader)):\n",
    "                logging.info('\\r Epoch:[%d/%d] Batch:[%d/%d] Loss:[%.4f] Acc:[%.2f] lr:[%.4f]'\n",
    "                                 % (epoch, cfg.num_epochs, i + 1, len(train_loader), train_losses_dict['ana_loss'].avg, train_acc_dict['accuracy'].avg,\n",
    "                                 optimizer.param_groups[0]['lr']))\n",
    "            step += 1\n",
    "\n",
    "        end_time = time.time()\n",
    "        logging.info(\"Epoch: {} Training time: {:.2f}\".format(epoch, end_time - st_time))\n",
    "        logging.info(\"========================validation========================\")\n",
    "        ana_model.eval()\n",
    "        with torch.no_grad():\n",
    "            step = 1\n",
    "            for i, val_batch in enumerate(val_loader):\n",
    "                images = torch.cat((val_batch['cover'], val_batch['stego']), 0).to(device, dtype=torch.float)\n",
    "                labels = torch.cat((val_batch['label'][0], val_batch['label'][1]), 0).to(device, dtype=torch.long)\n",
    "\n",
    "                outputs = ana_model(images)\n",
    "\n",
    "                ana_loss = criterion_ce(outputs, labels)\n",
    "\n",
    "                prediction = outputs.data.max(1)[1]\n",
    "                accuracy = prediction.eq(labels.data).sum() * 100.0 / (labels.size()[0])\n",
    "\n",
    "                val_losses_dict['ana_loss'].update(ana_loss.item(), images.size(0))\n",
    "                val_acc_dict['accuracy'].update(accuracy.item(), images.size(0))\n",
    "\n",
    "                if step % cfg.print_freq == 0 or step == (len(val_loader)):\n",
    "                    logging.info('\\r Epoch:[%d/%d] Batch:[%d/%d] Loss:[%.4f] Acc:[%.2f]'\n",
    "                                     % (epoch, cfg.num_epochs, i + 1, len(val_loader), val_losses_dict['ana_loss'].avg, val_acc_dict['accuracy'].avg))\n",
    "                step += 1\n",
    "        logging.info(\"========================validation========================\")\n",
    "\n",
    "        plot_scalars(epoch, run_folder, train_losses_dict, train_acc_dict, val_losses_dict, val_acc_dict)\n",
    "        save_checkpoint(epoch, run_folder, ana_model, optimizer, val_losses_dict, val_acc_dict)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
