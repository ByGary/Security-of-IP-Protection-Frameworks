{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722584e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import warnings\n",
    "\n",
    "from model.resnet import resnet18\n",
    "from train import train\n",
    "from validation import validation\n",
    "from test import test\n",
    "from data.data_loader import get_loader\n",
    "from utils import Ipynb_importer\n",
    "from utils.helper import *\n",
    "from utils.pytorchtools import EarlyStopping\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cfg = load_config()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = torch.device(cfg.system.device)\n",
    "run_folder = create_folder(cfg.results.run_folder)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s',\n",
    "                    handlers=[logging.FileHandler(os.path.join(run_folder, f'run.log')),\n",
    "                              logging.StreamHandler(sys.stdout)])\n",
    "logging.info(\"Experiment Configuration:\")\n",
    "logging.info(\"CUDA_VISIBLE_DEVICES：{}\".format(os.getenv('CUDA_VISIBLE_DEVICES')))\n",
    "logging.info(cfg)\n",
    "logging.info(\"run_folder:{}\".format(run_folder))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = False\n",
    "    if cfg.train.seed is not None:\n",
    "        np.random.seed(cfg.train.seed)  # Numpy module.\n",
    "        random.seed(cfg.train.seed)  # Python random module.\n",
    "        torch.manual_seed(cfg.train.seed)  # Sets the seed for generating random numbers.\n",
    "        torch.cuda.manual_seed(cfg.train.seed)  # Sets the seed for generating random numbers for the current GPU.\n",
    "        torch.cuda.manual_seed_all(cfg.train.seed)  # Sets the seed for generating random numbers on all GPUs.\n",
    "        cudnn.deterministic = True\n",
    "\n",
    "        warnings.warn('You have chosen to seed training. '\n",
    "                      'This will turn on the CUDNN deterministic setting, '\n",
    "                      'which can slow down your training considerably! '\n",
    "                      'You may see unexpected behavior when restarting '\n",
    "                      'from checkpoints.')\n",
    "        logging.info('torch.cuda is available!')\n",
    "\n",
    "# data loaders\n",
    "train_loader, val_loader, test_loader = get_loader(cfg, 'train'), get_loader(cfg, 'val'), get_loader(cfg, 'test')\n",
    "logging.info(\"train_loader:{} val_loadder:{} test_loader:{}\".format(len(train_loader.dataset), len(val_loader.dataset), len(test_loader.dataset)))\n",
    "# model training\n",
    "model = resnet18()\n",
    "model = nn.DataParallel(model.to(device))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=cfg.train.lr, momentum=cfg.train.momentum, weight_decay=cfg.train.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=cfg.train.lr_patience, verbose=True)  # patience为默认值\n",
    "\n",
    "logging.info(\"\\nModel Structure:\")\n",
    "logging.info(model)\n",
    "\n",
    "\n",
    "def main():\n",
    "    best_acc, best_acc_epoch = 0.0, 0\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=cfg.train.es_patience, verbose=True, trace_func=logging.info)\n",
    "\n",
    "    for epoch in range(cfg.train.start_epoch, cfg.train.num_epochs + 1):\n",
    "        logging.info('\\nStarting epoch {}/{}'.format(epoch, cfg.train.num_epochs))\n",
    "        logging.info('Batch size = {}\\nSteps in epoch = {}'.format(cfg.train.batch_size, len(train_loader)))\n",
    "\n",
    "        train_metrics = train(epoch, run_folder, cfg, device, train_loader, optimizer, criterion, model)\n",
    "\n",
    "        val_metrics = validation(epoch, run_folder, cfg, device, val_loader, criterion, model)\n",
    "\n",
    "        plot_scalars(epoch, run_folder, train_metrics, val_metrics)\n",
    "\n",
    "        val_loss, acc, prec, recall, f1 = val_metrics['Loss'], val_metrics['Acc'], val_metrics['Prec'], val_metrics['Recall'], val_metrics['F1']\n",
    "\n",
    "        if acc > best_acc:\n",
    "            save_checkpoint(epoch, model, optimizer, val_metrics, run_folder)\n",
    "            best_acc = acc\n",
    "            best_acc_epoch = epoch\n",
    "\n",
    "        # adjust the learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        logging.info(\"lr after adjusting:{}\".format(optimizer.param_groups[0]['lr']))\n",
    "\n",
    "        # Early_stopping needs the validation loss to check if it has decresed,\n",
    "        # and if it has, it will make a checkpoint of the current model.\n",
    "        early_stopping(val_loss, model, epoch=epoch, optimizer=optimizer, val_metrics=val_metrics)\n",
    "        if early_stopping.early_stop:\n",
    "            logging.info(\"The training should be early stopped now.\")\n",
    "            break\n",
    "\n",
    "    logging.info(\"################## Finished ##################\")\n",
    "    logging.info(\"In epoch {}: best acc: {:.4%}\".format(best_acc_epoch, best_acc))\n",
    "\n",
    "    logging.info(\"################## Testing... ##################\")\n",
    "    test(run_folder, cfg, device, test_loader, criterion, model)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
