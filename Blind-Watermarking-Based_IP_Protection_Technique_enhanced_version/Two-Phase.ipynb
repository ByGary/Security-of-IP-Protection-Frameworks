{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e4753a-4e23-4b4d-97ed-a69766431655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1\n",
    "from itertools import cycle\n",
    "\n",
    "from data.load_data import *\n",
    "from network.resnet import resnet18\n",
    "from utils.AverageMeter import AverageMeter\n",
    "from utils.helper import *\n",
    "from utils.pytorchtools import tuned_EarlyStopping\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cfg = load_config()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = torch.device(cfg.system.device)\n",
    "run_folder = create_folder(cfg.results.run_folder)\n",
    "# Print the configuration.\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s', handlers=[logging.FileHandler(os.path.join(run_folder, f'run.log')), logging.StreamHandler(sys.stdout)])\n",
    "logging.info(\"Experiment Configuration:\")\n",
    "logging.info(\"CUDA_VISIBLE_DEVICES：{}\".format(os.getenv('CUDA_VISIBLE_DEVICES')))\n",
    "logging.info(cfg)\n",
    "logging.info(\"run_folder:{}\".format(run_folder))\n",
    "# to be reproducible\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    if cfg.train.seed is not None:\n",
    "        np.random.seed(cfg.train.seed)  # Numpy module.\n",
    "        random.seed(cfg.train.seed)  # Python random module.\n",
    "        torch.manual_seed(cfg.train.seed)  # Sets the seed for generating random numbers.\n",
    "        torch.cuda.manual_seed(cfg.train.seed)  # Sets the seed for generating random numbers for the current GPU.\n",
    "        torch.cuda.manual_seed_all(cfg.train.seed)  # Sets the seed for generating random numbers on all GPUs.\n",
    "        cudnn.deterministic = True\n",
    "\n",
    "        warnings.warn('You have choosen to seed training. '\n",
    "                      'This will turn on the CUDNN deterministic setting, '\n",
    "                      'which can slow down your training considerably! '\n",
    "                      'You may see unexpected behavior when restarting '\n",
    "                      'from checkpoints.')\n",
    "\n",
    "# data loaders\n",
    "train_loader, val_loader, test_loader = get_loader(cfg, 'train'), get_loader(cfg, 'val'), get_loader(cfg, 'test')\n",
    "train_trigger_loader, val_trigger_loader, test_trigger_loader = get_loader(cfg, 'trigger_train'), get_loader(cfg, 'trigger_val'), get_loader(cfg, 'trigger_test'), \n",
    "logging.info(\"train_loader:{} val_loader:{} test_loader:{}\\n\".format(len(train_loader.dataset), len(val_loader.dataset), len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def load_pretrained():\n",
    "\n",
    "    if cfg.train.fine_tuning is True:\n",
    "        dnn_ckp_path = ''  # Fill in the checkpoint of host DNN.\n",
    "        dnn_ckp = torch.load(dnn_ckp_path)\n",
    "        Dnnet.load_state_dict(dnn_ckp[''])  # model weights\n",
    "        optimizerN.load_state_dict(dnn_ckp[''])  # parameters of the optimizer\n",
    "\n",
    "        logging.info(\"At checkpoint\" + '=' * 60)\n",
    "\n",
    "        pg_dict = dnn_ckp['optimizer_state_dict']['param_groups'][0]\n",
    "        logging.info(\"dnn_ckp: lr:{} momentum: {} weight_decay:{}\".format(pg_dict['lr'], pg_dict['momentum'], pg_dict['weight_decay']))\n",
    "        pg = optimizerN.param_groups[0]\n",
    "        logging.info(\"optimizerN: lr:{} momentum:{} weight_decay:{}\".format(pg['lr'], pg['momentum'], pg['weight_decay']))\n",
    "\n",
    "        logging.info(\"Epoch：{} val_loss：{:.4f} acc：{:.4%} prec：{:.4%} recall：{:.4%} f1：{:.4%}\".format(\n",
    "            dnn_ckp['epoch'], dnn_ckp['val_loss'], dnn_ckp['acc'], dnn_ckp['prec'], dnn_ckp['recall'], dnn_ckp['f1']))\n",
    "\n",
    "        logging.info(\"At checkpoint\" + '=' * 60)\n",
    "        logging.info(\"Have loaded pretrained ResNet.\\n\")\n",
    "\n",
    "\n",
    "# model\n",
    "Dnnet = resnet18()\n",
    "Dnnet = nn.DataParallel(Dnnet.to(device))\n",
    "# optimization\n",
    "criterionN = nn.CrossEntropyLoss()\n",
    "optimizerN = optim.SGD(Dnnet.parameters(), lr=cfg.train.lr, momentum=cfg.train.momentum, weight_decay=cfg.train.weight_decay)\n",
    "schedulerN = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizerN, mode='min', factor=0.1, patience=20, verbose=True)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    logging.info('\\nTraining epoch: %d' % epoch)\n",
    "\n",
    "    Dnnet.train()\n",
    "\n",
    "    step = 1\n",
    "    total_duration = 0\n",
    "    real_preds, real_trues, trigger_preds, trigger_trues = [], [], [], []\n",
    "    # Save relevant metrics in dictionaries.\n",
    "    losses_dict = defaultdict(AverageMeter)\n",
    "    metrics_dict = defaultdict()\n",
    "\n",
    "    real_acc = Accuracy(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "    precision = Precision(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "    recall = Recall(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "    f1 = F1(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "    trigger_acc = Accuracy(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "\n",
    "    for batch_idx, data in enumerate(zip(train_loader, cycle(train_trigger_loader))):\n",
    "\n",
    "        input, label = data[0][0].to(device), data[0][1].to(device)\n",
    "        trigger, trigger_label = data[1][0].to(device), data[1][1].to(device)\n",
    "        \"\"\"############################### Dnnet ###############################\"\"\"\n",
    "        inputs = torch.cat([input, trigger.detach()], dim=0)\n",
    "        labels = torch.cat([label, trigger_label], dim=0)\n",
    "\n",
    "        dnn_cat_output = Dnnet(inputs)\n",
    "        real_output = dnn_cat_output[0:cfg.train.batchsize]\n",
    "        trigger_output = dnn_cat_output[cfg.train.batchsize:]\n",
    "\n",
    "        loss_cat_Dnn = criterionN(dnn_cat_output, labels)\n",
    "        loss_real = criterionN(real_output, label)\n",
    "        loss_trigger = criterionN(trigger_output, trigger_label)\n",
    "\n",
    "        optimizerN.zero_grad()\n",
    "        loss_cat_Dnn.backward()\n",
    "        optimizerN.step()\n",
    "        \"\"\"############################### metrics ###############################\"\"\"\n",
    "\n",
    "        real_pred = dnn_cat_output[0:cfg.train.batchsize].argmax(dim=1)\n",
    "        trigger_pred = dnn_cat_output[cfg.train.batchsize:].argmax(dim=1)\n",
    "\n",
    "        real_preds.extend(real_pred.cpu().numpy())\n",
    "        real_trues.extend(label.cpu().numpy())\n",
    "        trigger_preds.extend(trigger_pred.cpu().numpy())\n",
    "        trigger_trues.extend(trigger_label.cpu().numpy())\n",
    "\n",
    "        real_acc.update(real_pred.cpu(), label.cpu())\n",
    "        precision.update(real_pred.cpu(), label.cpu())\n",
    "        recall.update(real_pred.cpu(), label.cpu())\n",
    "        f1.update(real_pred.cpu(), label.cpu())\n",
    "        trigger_acc.update(trigger_pred.cpu(), trigger_label.cpu())\n",
    "\n",
    "        temp_losses_dict = {\n",
    "            'loss_cat_Dnn': loss_cat_Dnn.item(),\n",
    "            'loss_real': loss_real.item(),\n",
    "            'loss_trigger': loss_trigger.item()\n",
    "        }\n",
    "        for tag, metric in temp_losses_dict.items():\n",
    "            if tag == 'loss_cat_Dnn':\n",
    "                losses_dict[tag].update(metric, inputs.size(0))\n",
    "            elif tag == 'loss_real':\n",
    "                losses_dict[tag].update(metric, input.size(0))\n",
    "            else:\n",
    "                losses_dict[tag].update(metric, trigger.size(0))\n",
    "\n",
    "        if step % cfg.train.print_freq == 0 or step == (len(train_loader)):\n",
    "            logging.info('[{}/{}][{}/{}] '\n",
    "                'Loss_cat_Dnn: {:.4f} Loss_real：{:.4f} Loss_trigger：{:.4f}'.format(epoch, cfg.train.num_epochs, step, len(train_loader),\n",
    "                    losses_dict['loss_cat_Dnn'].avg, losses_dict['loss_real'].avg, losses_dict['loss_trigger'].avg))\n",
    "\n",
    "            logging.info(\"Real acc: {:.4%} Trigger acc: {:.4%} \"\n",
    "                         \"Prec: {:.4%} Recall: {:.4%} F1: {:.4%}\".format(\n",
    "                             real_acc.compute(), trigger_acc.compute(), precision.compute(), recall.compute(), f1.compute()))\n",
    "            logging.info('-' * 130)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    total_duration = time.time() - epoch_start_time\n",
    "    logging.info('Epoch {} total duration: {:.2f} sec'.format(epoch, total_duration))\n",
    "    logging.info('-' * 130)\n",
    "\n",
    "    metrics_dict['real_acc'] = real_acc.compute()\n",
    "    metrics_dict['precision'] = precision.compute()\n",
    "    metrics_dict['recall'] = recall.compute()\n",
    "    metrics_dict['f1'] = f1.compute()\n",
    "    metrics_dict['trigger_acc'] = trigger_acc.compute()\n",
    "\n",
    "    write_scalars(epoch, os.path.join(run_folder, 'train.csv'), losses_dict, metrics_dict, None, total_duration)\n",
    "\n",
    "    return losses_dict, metrics_dict\n",
    "\n",
    "\n",
    "def validation(epoch):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    logging.info('#' * 130)\n",
    "    logging.info('Running validation for epoch {}/{}'.format(epoch, cfg.train.num_epochs))\n",
    "\n",
    "    Dnnet.eval()\n",
    "\n",
    "    total_duration = 0\n",
    "    real_preds, real_trues, trigger_preds, trigger_trues = [], [], [], []\n",
    "    # Save relevant metrics in dictionaries.\n",
    "    losses_dict = defaultdict(AverageMeter)\n",
    "    metrics_dict = defaultdict()\n",
    "\n",
    "    real_acc = Accuracy(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "    precision = Precision(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "    recall = Recall(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "    f1 = F1(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "    trigger_acc = Accuracy(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(zip(val_loader, cycle(val_trigger_loader))):\n",
    "            input, label = data[0][0].to(device), data[0][1].to(device)\n",
    "            trigger, trigger_label = data[1][0].to(device), data[1][1].to(device)\n",
    "            \"\"\"############################### Dnnet ###############################\"\"\"\n",
    "            inputs = torch.cat([input, trigger.detach()], dim=0)\n",
    "            labels = torch.cat([label, trigger_label], dim=0)\n",
    "\n",
    "            dnn_cat_output = Dnnet(inputs)\n",
    "            real_output = dnn_cat_output[0:cfg.train.batchsize]\n",
    "            trigger_output = dnn_cat_output[cfg.train.batchsize:]\n",
    "\n",
    "            loss_cat_Dnn = criterionN(dnn_cat_output, labels)\n",
    "            loss_real = criterionN(real_output, label)\n",
    "            loss_trigger = criterionN(trigger_output, trigger_label)\n",
    "            \"\"\"############################### metrics ###############################\"\"\"\n",
    "            real_pred = dnn_cat_output[0:cfg.train.batchsize].argmax(dim=1)\n",
    "            trigger_pred = dnn_cat_output[cfg.train.batchsize:].argmax(dim=1)\n",
    "\n",
    "            real_preds.extend(real_pred.cpu().numpy())\n",
    "            real_trues.extend(label.cpu().numpy())\n",
    "            trigger_preds.extend(trigger_pred.cpu().numpy())\n",
    "            trigger_trues.extend(trigger_label.cpu().numpy())\n",
    "\n",
    "            real_acc.update(real_pred.cpu(), label.cpu())\n",
    "            precision.update(real_pred.cpu(), label.cpu())\n",
    "            recall.update(real_pred.cpu(), label.cpu())\n",
    "            f1.update(real_pred.cpu(), label.cpu())\n",
    "            trigger_acc.update(trigger_pred.cpu(), trigger_label.cpu())\n",
    "\n",
    "            temp_losses_dict = {\n",
    "                'loss_cat_Dnn': loss_cat_Dnn.item(),\n",
    "                'loss_real': loss_real.item(),\n",
    "                'loss_trigger': loss_trigger.item()\n",
    "            }\n",
    "            for tag, metric in temp_losses_dict.items():\n",
    "                if tag == 'loss_cat_Dnn':\n",
    "                    losses_dict[tag].update(metric, inputs.size(0))\n",
    "                elif tag == 'loss_real':\n",
    "                    losses_dict[tag].update(metric, input.size(0))\n",
    "                else:\n",
    "                    losses_dict[tag].update(metric, trigger.size(0))\n",
    "\n",
    "    logging.info(\n",
    "        '[{}/{}] Loss_cat_Dnn: {:.4f}  Loss_real：{:.4f} Loss_trigger：{:.4f}'.format(\n",
    "            epoch, cfg.train.num_epochs,\n",
    "            losses_dict['loss_cat_Dnn'].avg, losses_dict['loss_real'].avg, losses_dict['loss_trigger'].avg))\n",
    "    logging.info(\"Real acc: {:.4%} Trigger acc: {:.4%} \"\n",
    "                 \"Precision: {:.4%} Recall: {:.4%} F1: {:.4%}\".format(real_acc.compute(), trigger_acc.compute(),\n",
    "                                                                                                        precision.compute(), recall.compute(), f1.compute()))\n",
    "\n",
    "    total_duration = time.time() - epoch_start_time\n",
    "    logging.info('Epoch {} total duration: {:.2f} sec'.format(epoch, total_duration))\n",
    "    logging.info('#' * 130)\n",
    "\n",
    "    metrics_dict['real_acc'] = real_acc.compute()\n",
    "    metrics_dict['precision'] = precision.compute()\n",
    "    metrics_dict['recall'] = recall.compute()\n",
    "    metrics_dict['f1'] = f1.compute()\n",
    "    metrics_dict['trigger_acc'] = trigger_acc.compute()\n",
    "\n",
    "    write_scalars(epoch, os.path.join(run_folder, 'val.csv'), losses_dict, metrics_dict, None, total_duration)\n",
    "\n",
    "    return losses_dict, metrics_dict\n",
    "\n",
    "\n",
    "def test():\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    Dnnet.eval()\n",
    "\n",
    "    test_duration = 0\n",
    "    real_preds, real_trues, trigger_preds, trigger_trues = [], [], [], []\n",
    "\n",
    "    losses_dict = defaultdict(AverageMeter)\n",
    "    metrics_dict = defaultdict()\n",
    "\n",
    "    real_acc = Accuracy(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "    precision = Precision(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "    recall = Recall(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "    f1 = F1(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "    trigger_acc = Accuracy(num_classes=cfg.dataset.num_classes, average='weighted')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(zip(test_loader, cycle(test_trigger_loader))):\n",
    "            input, label = data[0][0].to(device), data[0][1].to(device)\n",
    "            trigger, trigger_label = data[1][0].to(device), data[1][1].to(device)\n",
    "            \"\"\"############################### Dnnet ###############################\"\"\"\n",
    "            \n",
    "            inputs = torch.cat([input, trigger.detach()], dim=0)\n",
    "            labels = torch.cat([label, trigger_label], dim=0)\n",
    "            \n",
    "            dnn_cat_output = Dnnet(inputs)\n",
    "            real_output = dnn_cat_output[0:cfg.train.batchsize]\n",
    "            trigger_output = dnn_cat_output[cfg.train.batchsize:]\n",
    "\n",
    "            loss_cat_Dnn = criterionN(dnn_cat_output, labels)\n",
    "            loss_real = criterionN(real_output, label)\n",
    "            loss_trigger = criterionN(trigger_output, trigger_label)\n",
    "            \"\"\"############################### metrics ###############################\"\"\"\n",
    "            \n",
    "            real_pred = dnn_cat_output[0:cfg.train.batchsize].argmax(dim=1)\n",
    "            trigger_pred = dnn_cat_output[cfg.train.batchsize:].argmax(dim=1)\n",
    "            \n",
    "            real_preds.extend(real_pred.cpu().numpy())\n",
    "            real_trues.extend(label.cpu().numpy())\n",
    "            trigger_preds.extend(trigger_pred.cpu().numpy())\n",
    "            trigger_trues.extend(trigger_label.cpu().numpy())\n",
    "            \n",
    "            real_acc.update(real_pred.cpu(), label.cpu())\n",
    "            precision.update(real_pred.cpu(), label.cpu())\n",
    "            recall.update(real_pred.cpu(), label.cpu())\n",
    "            f1.update(real_pred.cpu(), label.cpu())\n",
    "            trigger_acc.update(trigger_pred.cpu(), trigger_label.cpu())\n",
    "\n",
    "            temp_losses_dict = {\n",
    "                'loss_cat_Dnn': loss_cat_Dnn.item(),\n",
    "                'loss_real': loss_real.item(),\n",
    "                'loss_trigger': loss_trigger.item()\n",
    "            }\n",
    "            for tag, metric in temp_losses_dict.items():\n",
    "                if tag == 'loss_cat_Dnn':\n",
    "                    losses_dict[tag].update(metric, inputs.size(0))\n",
    "                elif tag == 'loss_real':\n",
    "                    losses_dict[tag].update(metric, input.size(0))\n",
    "                else:\n",
    "                    losses_dict[tag].update(metric, trigger.size(0))\n",
    "\n",
    "    logging.info(\n",
    "        'Loss_cat_Dnn: {:.4f} Loss_real：{:.4f} Loss_trigger：{:.4f}'.format(\n",
    "            losses_dict['loss_cat_Dnn'].avg, losses_dict['loss_real'].avg, losses_dict['loss_trigger'].avg))\n",
    "    logging.info(\"Real acc: {:.4%} Trigger acc: {:.4%} \"\n",
    "                 \"Precision: {:.4%} Recall: {:.4%} F1: {:.4%}\".format(real_acc.compute(), trigger_acc.compute(), \n",
    "                                                                                   precision.compute(), precision.compute(), recall.compute(), f1.compute()))\n",
    "\n",
    "    test_duration = time.time() - epoch_start_time\n",
    "    logging.info('test duration {:.2f} sec'.format(test_duration))\n",
    "\n",
    "    metrics_dict['real_acc'] = real_acc.compute()\n",
    "    metrics_dict['precision'] = precision.compute()\n",
    "    metrics_dict['recall'] = recall.compute()\n",
    "    metrics_dict['f1'] = f1.compute()\n",
    "    metrics_dict['trigger_acc'] = trigger_acc.compute()\n",
    "\n",
    "    write_scalars(1, os.path.join(run_folder, 'test.csv'), losses_dict, metrics_dict, None, test_duration)\n",
    "    # confusion matrix\n",
    "    plot_confusion_matrix(1, run_folder, 'test_real', real_preds, real_trues, test_loader)\n",
    "    plot_confusion_matrix(1, run_folder, 'test_trigger', trigger_preds, trigger_trues, None)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Early stop the training according to real_loss, trigger_loss and cat_loss respectively.\n",
    "    early_real_loss = tuned_EarlyStopping(patience=cfg.train.es_patience, verbose=True, trace_func=logging.info)\n",
    "    early_trigger_loss = tuned_EarlyStopping(patience=cfg.train.es_patience, verbose=True, trace_func=logging.info)\n",
    "    early_cat_loss = tuned_EarlyStopping(patience=cfg.train.es_patience, verbose=True, trace_func=logging.info)\n",
    "    # whether follow the early stopping mechanism\n",
    "    real_go_on, trigger_go_on, cat_go_on = True, True, True\n",
    "\n",
    "    load_pretrained()\n",
    "\n",
    "    for epoch in range(cfg.train.start_epoch, cfg.train.num_epochs + 1):\n",
    "\n",
    "        train_losses_dict, train_metrics_dict = train(epoch)\n",
    "        val_losses_dict, val_metrics_dict = validation(epoch)\n",
    "\n",
    "        logging.info(\"Learning rate of ResNet:{}\".format(optimizerN.param_groups[0]['lr']))\n",
    "\n",
    "        plot_scalars(epoch, run_folder, train_losses_dict, train_metrics_dict, val_losses_dict, val_metrics_dict, None)\n",
    "\n",
    "        schedulerN.step(val_losses_dict['loss_cat_Dnn'].avg)\n",
    "\n",
    "        if real_go_on is True:\n",
    "            early_real_loss(val_losses_dict['loss_real'].avg, epoch, run_folder, Dnnet, optimizerN, val_losses_dict, val_metrics_dict, 'loss_real')\n",
    "            if early_real_loss.early_stop:\n",
    "                logging.info(\"The training has gained minimum real loss at {}th epoch\".format(epoch))\n",
    "                real_go_on = False\n",
    "\n",
    "        if trigger_go_on is True:\n",
    "            early_trigger_loss(val_losses_dict['loss_trigger'].avg, epoch, run_folder, Dnnet, optimizerN, val_losses_dict, val_metrics_dict, 'loss_trigger')\n",
    "            if early_trigger_loss.early_stop:\n",
    "                logging.info(\"The training has gained minimum trigger loss at {}th epoch\".format(epoch))\n",
    "                trigger_go_on = False\n",
    "\n",
    "        if cat_go_on is True:\n",
    "            early_cat_loss(val_losses_dict['loss_cat_Dnn'].avg, epoch, run_folder, Dnnet, optimizerN, val_losses_dict, val_metrics_dict, 'loss_cat_Dnn')\n",
    "            if early_cat_loss.early_stop:\n",
    "                logging.info(\"The training has gained minimum cat_loss at {}th epoch\".format(epoch))\n",
    "                cat_go_on = False\n",
    "        # Due to unexpected fluctuations during training, every checkpoint is expected to be saved despite the early stopping mechanism.\n",
    "        save_tuned_host(epoch, run_folder, Dnnet, optimizerN, val_losses_dict, val_metrics_dict)\n",
    "\n",
    "\n",
    "    logging.info(\"################## Finished ##################\")\n",
    "\n",
    "    if cfg.test is True:\n",
    "        logging.info(\"################## Testing... ##################\")\n",
    "        tuned_pt_root = ''  # where you store the checkpoints\n",
    "        tuned_ste_path, tuned_dnn_path = os.path.join(tuned_pt_root, ''), os.path.join(tuned_pt_root, '')  # Fill in paths of trained steganography and fine-tuned host model respectively.\n",
    "        tuned_ste, tuned_dnn = torch.load(tuned_ste_path), torch.load(tuned_dnn_path)\n",
    "        # model weights\n",
    "        ste_model.load_state_dict(tuned_ste[''])\n",
    "        Dnnet.load_state_dict(tuned_dnn[''])\n",
    "        logging.info(\"Have loaded model checkpoints from '{}'\".format(tuned_pt_root))\n",
    "\n",
    "        logging.info(\"Fine-tuned model at checkpoint\" + '=' * 60)\n",
    "        logging.info(\"Loss_H: {:.4f} (loss_hid: {:.4f} loss_rev: {:.4f} loss_dnn: {:.4f}) Loss_cat_Dnn: {:.4f} Loss_real：{:.4f} Loss_trigger：{:.4f}\".format(\n",
    "            tuned_ste['loss_H'], tuned_ste['loss_hid'], tuned_ste['loss_rev'], tuned_ste['loss_dnn'], tuned_dnn['loss_cat_Dnn'], tuned_dnn['loss_real'], tuned_dnn['loss_trigger']))\n",
    "        logging.info(\"Real acc: {:.4%} Trigger acc: {:.4%} Cover acc: {:.4%} Precision: {:.4%} Recall: {:.4%} F1: {:.4%} ste_psnr: {:.2f} rev_psnr: {:.2f}\".format(\n",
    "            tuned_dnn['real_acc'], tuned_dnn['trigger_acc'], tuned_dnn['cover_acc'], tuned_dnn['precision'], tuned_dnn['recall'], tuned_dnn['f1'], tuned_ste['ste_psnr'], tuned_ste['rev_psnr']))\n",
    "        logging.info(\"Fine-tuned model at checkpoint\" + '=' * 60)\n",
    "\n",
    "        test_cover_imgs, test_cover_img_labels, test_wms, test_wm_labels = load_cover_and_wm(cfg, 'cover_test')\n",
    "        logging.info(\"test_cover_img_labels:{} test_cover_img_labels[0]:{} test_wm_labels:{} test_wm_labels[0]:{}\".format(len(test_cover_img_labels), test_cover_img_labels[0], len(test_wm_labels), test_wm_labels[0]))\n",
    "        test(test_cover_imgs, test_cover_img_labels, test_wms, test_wm_labels)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
