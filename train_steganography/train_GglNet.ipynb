{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33e7a7-9c0a-4247-a942-d5d45d1d20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "import sys\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.backends import cudnn\n",
    "from collections import defaultdict\n",
    "\n",
    "from load_data.load_ste_data import *\n",
    "from algorithm.GoogleNet import GoogleNet\n",
    "from utils.AverageMeter import AverageMeter\n",
    "from utils.helper import *\n",
    "from utils.pytorchtools import EarlyStopping\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cfg = load_config()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = torch.device(cfg.system.device)\n",
    "run_folder = create_folder(cfg.results.run_folder)\n",
    "# Print the configuration.\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s', handlers=[\n",
    "    logging.FileHandler(os.path.join(run_folder, f'run.log')), logging.StreamHandler(sys.stdout)])\n",
    "logging.info(\"Experiment Configuration:\")\n",
    "logging.info(\"CUDA_VISIBLE_DEVICESï¼š{}\".format(os.getenv('CUDA_VISIBLE_DEVICES')))\n",
    "logging.info(cfg)\n",
    "logging.info(\"run_folder:{}\".format(run_folder))\n",
    "# to be reproducible\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    if cfg.train.seed is not None:\n",
    "        np.random.seed(cfg.train.seed)  # Numpy module.\n",
    "        random.seed(cfg.train.seed)  # Python random module.\n",
    "        torch.manual_seed(cfg.train.seed)  # Sets the seed for generating random numbers.\n",
    "        torch.cuda.manual_seed(cfg.train.seed)  # Sets the seed for generating random numbers for the current GPU.\n",
    "        torch.cuda.manual_seed_all(cfg.train.seed)  # Sets the seed for generating random numbers on all GPUs.\n",
    "        cudnn.deterministic = True\n",
    "\n",
    "        warnings.warn('You have choosen to seed training. '\n",
    "                      'This will turn on the CUDNN deterministic setting, '\n",
    "                      'which can slow down your training considerably! '\n",
    "                      'You may see unexpected behavior when restarting '\n",
    "                      'from checkpoints.')\n",
    "        logging.info('torch.cuda is available!')\n",
    "\n",
    "# model\n",
    "ste_model = GoogleNet().to(device)\n",
    "ste_model = nn.DataParallel(ste_model.to(device))\n",
    "# optimization\n",
    "criterion_mse = nn.MSELoss()\n",
    "optimizer = optim.Adam(ste_model.parameters(), lr=cfg.train.lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5)\n",
    "# data loaders\n",
    "cover_train_loader, cover_val_loader = get_loader(cfg, 'cover_train'), get_loader(cfg, 'cover_val')\n",
    "logging.info(\"cover_train_loader:{} cover_val_loader:{}\".format(len(cover_train_loader.dataset), len(cover_val_loader.dataset)))\n",
    "\n",
    "secret_train_loader, secret_val_loader = get_loader(cfg, 'secret_train'), get_loader(cfg, 'secret_val')\n",
    "logging.info(\"secret_train_loader:{} secret_val_loader:{}\".format(len(secret_train_loader.dataset), len(secret_val_loader.dataset)))\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    epoch_duration = 0\n",
    "\n",
    "    logging.info('Training epoch: %d' % epoch)\n",
    "    ste_model.train()\n",
    "    step = 1\n",
    "\n",
    "    # Save relevant metrics in dictionaries.\n",
    "    losses_dict = defaultdict(AverageMeter)\n",
    "    img_quality_dict = defaultdict(AverageMeter)  # PSNR\n",
    "\n",
    "    for batch_idx, data in enumerate(zip(cover_train_loader, secret_train_loader)):\n",
    "        cover_img, secret_img = data[0][0].to(device), data[1][0].to(device)\n",
    "\n",
    "        ste_img, ex_secret = ste_model(cover_img, secret_img)\n",
    "\n",
    "        loss_hid = criterion_mse(cover_img, ste_img)\n",
    "        loss_rev = criterion_mse(secret_img, ex_secret)\n",
    "        loss_ste = loss_hid + loss_rev\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_ste.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_duration += time.time() - epoch_start_time\n",
    "\n",
    "        temp_losses_dict = {\n",
    "            'loss_hid': loss_hid.item(),\n",
    "            'loss_rev': loss_rev.item(),\n",
    "            'loss_ste': loss_ste.item()\n",
    "        }\n",
    "        for tag, metric in temp_losses_dict.items():\n",
    "            losses_dict[tag].update(metric, cover_img.size(0))\n",
    "\n",
    "        ste_psnr = cal_psnr(cover_img, ste_img.detach())\n",
    "        ex_psnr = cal_psnr(secret_img, ex_secret.detach())\n",
    "        img_quality_dict['ste_psnr'].update(ste_psnr, ste_img.size(0))\n",
    "        img_quality_dict['ex_psnr'].update(ex_psnr, ex_secret.size(0))\n",
    "\n",
    "        if step % cfg.train.print_freq == 0 or step == (len(cover_train_loader)):\n",
    "            logging.info('[{}/{}][{}/{}] loss_ste: {:.4f} (loss_hid: {:.4f} loss_rev: {:.4f}) ste_PSNR: {:.2f} ex_PSNR: {:.2f}'.format(\n",
    "                    epoch, cfg.train.num_epochs, step, len(cover_train_loader),\n",
    "                    losses_dict['loss_ste'].avg, losses_dict['loss_hid'].avg, losses_dict['loss_rev'].avg, ste_psnr, ex_psnr))\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    epoch_duration = time.time() - epoch_start_time\n",
    "    logging.info('Training duration of epoch {}: {:.2f} sec'.format(epoch, epoch_duration))\n",
    "\n",
    "    save_cat_image(cfg, epoch, run_folder, cover_img, ste_img, secret_img, ex_secret, 'train')\n",
    "    write_scalars(epoch, os.path.join(run_folder, 'train.csv'), losses_dict, img_quality_dict, epoch_duration)\n",
    "\n",
    "    return losses_dict, img_quality_dict\n",
    "\n",
    "\n",
    "def validation(epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    epoch_duration = 0\n",
    "\n",
    "    logging.info(\"========================validation========================\")\n",
    "    ste_model.eval()\n",
    "    step = 1\n",
    "\n",
    "    # Save relevant metrics in dictionaries.\n",
    "    losses_dict = defaultdict(AverageMeter)\n",
    "    img_quality_dict = defaultdict(AverageMeter)  # PSNR\n",
    "\n",
    "    for batch_idx, data in enumerate(zip(cover_val_loader, secret_val_loader)):\n",
    "        cover_img, secret_img = data[0][0].to(device), data[1][0].to(device)\n",
    "\n",
    "        ste_img, ex_secret = ste_model(cover_img, secret_img)\n",
    "\n",
    "        loss_hid = criterion_mse(cover_img, ste_img)\n",
    "        loss_rev = criterion_mse(secret_img, ex_secret)\n",
    "        loss_ste = loss_hid + loss_rev\n",
    "\n",
    "        epoch_duration += time.time() - epoch_start_time\n",
    "\n",
    "        temp_losses_dict = {\n",
    "            'loss_hid': loss_hid.item(),\n",
    "            'loss_rev': loss_rev.item(),\n",
    "            'loss_ste': loss_ste.item()\n",
    "        }\n",
    "        for tag, metric in temp_losses_dict.items():\n",
    "            losses_dict[tag].update(metric, cover_img.size(0))\n",
    "\n",
    "        ste_psnr = cal_psnr(cover_img, ste_img.detach())\n",
    "        ex_psnr = cal_psnr(secret_img, ex_secret.detach())\n",
    "        img_quality_dict['ste_psnr'].update(ste_psnr, ste_img.size(0))\n",
    "        img_quality_dict['ex_psnr'].update(ex_psnr, ex_secret.size(0))\n",
    "\n",
    "        if step % cfg.train.print_freq == 0 or step == (len(cover_val_loader)):\n",
    "            logging.info('[{}/{}][{}/{}] loss_ste: {:.4f} (loss_hid: {:.4f} loss_rev: {:.4f}) ste_PSNR: {:.2f} ex_PSNR: {:.2f}'.format(\n",
    "                epoch, cfg.train.num_epochs, step, len(cover_val_loader),\n",
    "                losses_dict['loss_ste'].avg, losses_dict['loss_hid'].avg, losses_dict['loss_rev'].avg, ste_psnr, ex_psnr))\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    logging.info(\"========================validation========================\")\n",
    "\n",
    "    epoch_duration = time.time() - epoch_start_time\n",
    "    logging.info('Validation duration of epoch{}: {:.2f} sec'.format(epoch, epoch_duration))\n",
    "\n",
    "    save_cat_image(cfg, epoch, run_folder, cover_img, ste_img, secret_img, ex_secret, 'val')\n",
    "    write_scalars(epoch, os.path.join(run_folder, 'val.csv'), losses_dict, img_quality_dict, epoch_duration)\n",
    "\n",
    "    return losses_dict, img_quality_dict\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Initialize the early stopping object.\n",
    "    early_loss = EarlyStopping(patience=cfg.train.es_patience, verbose=True, trace_func=logging.info)\n",
    "    # The checkpoint is not necessary when you decide to train the algorithm from scratch.\n",
    "    if cfg.train.has_ckp is True:\n",
    "        ste_ckp = torch.load(\"\")  # Fill in the path of your prepared checkpoint.\n",
    "        ste_model.load_state_dict(ste_ckp[''])  # model weight\n",
    "        optimizer.load_state_dict(ste_ckp[''])  # parameters of the optimizer\n",
    "        logging.info(\"Have loaded steganography checkpoint.\")\n",
    "\n",
    "    for epoch in range(cfg.train.start_epoch, cfg.train.num_epochs + 1):\n",
    "\n",
    "        train_losses_dict, train_img_quality_dict = train(epoch)\n",
    "        val_losses_dict, val_img_quality_dict = validation(epoch)\n",
    "        # visualize\n",
    "        plot_scalars(epoch, run_folder, train_losses_dict, train_img_quality_dict, val_losses_dict, val_img_quality_dict)\n",
    "\n",
    "        # Save checkpoints when loss decreased.\n",
    "        early_loss(epoch, run_folder, ste_model, optimizer, val_losses_dict, val_img_quality_dict)\n",
    "        if early_loss.early_stop:\n",
    "            logging.info(\"The training has gained minimum loss at {}th epoch\".format(epoch))\n",
    "            break\n",
    "\n",
    "    logging.info(\"################## finished ##################\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
